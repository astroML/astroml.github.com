

<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN"
  "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">


<html xmlns="http://www.w3.org/1999/xhtml">
  <head>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    
    <title>Huber Loss Function &mdash; astroML 0.1 documentation</title>
    
    <link rel="stylesheet" href="../../_static/astroMLstyle.css" type="text/css" />
    <link rel="stylesheet" href="../../_static/pygments.css" type="text/css" />
    
    <script type="text/javascript">
      var DOCUMENTATION_OPTIONS = {
        URL_ROOT:    '../../',
        VERSION:     '0.1',
        COLLAPSE_INDEX: false,
        FILE_SUFFIX: '.html',
        HAS_SOURCE:  true
      };
    </script>
    <script type="text/javascript" src="../../_static/jquery.js"></script>
    <script type="text/javascript" src="../../_static/underscore.js"></script>
    <script type="text/javascript" src="../../_static/doctools.js"></script>
    <link rel="top" title="astroML 0.1 documentation" href="../../index.html" />
    <link rel="up" title="Chapter 8: Regression and Model Fitting" href="index.html" />
    <link rel="next" title="Gaussian Process Example" href="fig_gp_example.html" />
    <link rel="prev" title="Huber Functional Form" href="fig_huber_func.html" />
<!-- Following code is for Google custom search bar -->
<script>
  (function() {
    var cx = '011400076584591653333:hjd_fbqk1u0';
    var gcse = document.createElement('script'); gcse.type = 'text/javascript'; gcse.async = true;
    gcse.src = (document.location.protocol == 'https:' ? 'https:' : 'http:') +
        '//www.google.com/cse/cse.js?cx=' + cx;
    var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(gcse, s);
  })();
</script>

<!-- Following code is for toggle/glide features -->
<script type="text/javascript" src="http://code.jquery.com/jquery-latest.js"></script>
<script type="text/javascript">
$(document).ready(function(){
	
	$(".toggle_container").hide();

	$(".toggle_trigger").click(function(){
		$(this).toggleClass("active").next(".toggle_container").slideToggle("fast");
                return false; <!-- Prevent the link from being followed -->
	});

        $(".toggle_trigger#start_open").toggleClass("active").next().show();

});
</script>

<!-- Following code is for Google Analytics -->
<script type="text/javascript">

  var _gaq = _gaq || [];
  _gaq.push(['_setAccount', 'UA-35748160-1']);
  _gaq.push(['_trackPageview']);

  (function() {
    var ga = document.createElement('script'); ga.type = 'text/javascript'; ga.async = true;
    ga.src = ('https:' == document.location.protocol ? 'https://ssl' : 'http://www') + '.google-analytics.com/ga.js';
    var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(ga, s);
  })();

</script>

  </head>
  <body>
    <div class="header-wrapper"
      <div class="header">
          <p class="logo"><a href="../../index.html">
            <img src="../../_static/Logo.gif" alt="Logo"/>
          </a>
          </p><div class="navbar">
          <ul>
            <li><a href="../../index.html">Home</a></li>
	    <li><a href="../../user_guide/index.html">User Guide</a></li>
            <li><a href="../index.html">Book Figures</a></li>
            <li><a href="../../examples/index.html">Examples Plots</a></li>
       </ul>

<!-- Google custom search.  Javascript that enables this is in the header above -->
<div class="search_form">
  <gcse:search></gcse:search>
</div>

          </div> <!-- end navbar --></div>
    </div>

    <div class="content-wrapper">

    <!-- <div id="blue_tile"></div> -->

        <div class="sphinxsidebar">
	<div class="rel">
	
	<!-- rellinks[1:] is an ugly hack to avoid link to module
	    index  -->
	<div class="rellink">
	<a href="fig_huber_func.html" title="Huber Functional Form"
	    accesskey="P">Previous
	    <br>
	    <span class="smallrellink">
	    Huber Functional...
	    </span>
	    <span class="hiddenrellink">
	    Huber Functional Form
	    </span>
	    
	    </a>
	</div>
	    <div class="spacer">
	    &nbsp;
	    </div>
	
	<div class="rellink">
	<a href="fig_gp_example.html" title="Gaussian Process Example"
	    accesskey="N">Next
	    <br>
	    <span class="smallrellink">
	    Gaussian Process...
	    </span>
	    <span class="hiddenrellink">
	    Gaussian Process Example
	    </span>
	    
	    </a>
	</div>
	<!-- Ad a link to the 'up' page -->
	<div class="spacer">
	&nbsp;
	</div>
	<div class="rellink">
	<a href="index.html" title="Chapter 8: Regression and Model Fitting" >
	Up
	<br>
	<span class="smallrellink">
	Chapter 8: Regre...
	</span>
	<span class="hiddenrellink">
	Chapter 8: Regression and Model Fitting
	</span>
	
	</a>
	</div>
    </div>
    <p style="text-align: center">This documentation is
    for astroML <strong>version 0.1</strong>
    <!-- &mdash; <a href="http://scikit-learn.org/stable/support.html#documentation-resources">Other versions</a></p> -->
        

	

        <h3>This page</h3>
         <ul>
<li><a class="reference internal" href="#">Huber Loss Function</a></li>
</ul>


        

	<h3>Links</h3>
	<p><a href="https://groups.google.com/forum/#!forum/astroml-general">astroML Mailing List</a></p>
	<p><a href="http://github.com/astroML/astroML/issues">GitHub Issue Tracker</a></p>


    <h3>Citing</h3>
    <p>If you use the software, please consider
    <a href="../../index.htmlciting-astroml">citing astroML</a>.</p>


        

        </div>

      <div class="content">
            
      <div class="documentwrapper">
        <div class="bodywrapper">
          <div class="body">
            
  <div class="section" id="huber-loss-function">
<span id="book-fig-chapter8-fig-huber-loss"></span><h1>Huber Loss Function<a class="headerlink" href="#huber-loss-function" title="Permalink to this headline">Â¶</a></h1>
<p>This example shows how to perform robust regression using the Huber
loss function.</p>
<p>Note that sklearn.linear_model.SGDRegressor has a Huber Loss Function
built-in; here we will not use this, because it cannot account for
heteroscedastic errors.</p>
<img alt="../../_images/fig_huber_loss_1.png" class="align-center" src="../../_images/fig_huber_loss_1.png" style="width: 100%;" />
<div class="toggle_trigger"><a href="#"><p><strong>Code output:</strong></p>
</a></div>
<div class="toggle_container"><div class="highlight-python"><pre>Optimization terminated successfully.
         Current function value: 289.963723
         Iterations: 62
         Function evaluations: 117
Optimization terminated successfully.
         Current function value: 43.439758
         Iterations: 59
         Function evaluations: 115
[   1.07674745  213.27350923]
[  1.96473118  70.00573832]
</pre>
</div>
</div>
<div class="toggle_trigger" id="start_open"><a href="#"><p><strong>Python source code:</strong></p>
</a></div>
<div class="toggle_container"><div class="highlight-python"><div class="highlight"><pre><span class="c"># Author: Jake VanderPlas &lt;vanderplas@astro.washington.edu&gt;</span>
<span class="c"># License: BSD</span>
<span class="c">#   The figure produced by this code is published in the textbook</span>
<span class="c">#   &quot;Statistics, Data Mining, and Machine Learning in Astronomy&quot; (2013)</span>
<span class="c">#   For more information, see http://astroML.github.com</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="kn">as</span> <span class="nn">np</span>
<span class="kn">from</span> <span class="nn">matplotlib</span> <span class="kn">import</span> <span class="n">pyplot</span> <span class="k">as</span> <span class="n">plt</span>

<span class="kn">from</span> <span class="nn">scipy</span> <span class="kn">import</span> <span class="n">optimize</span>
<span class="kn">from</span> <span class="nn">astroML.datasets</span> <span class="kn">import</span> <span class="n">fetch_hogg2010test</span>

<span class="c">#------------------------------------------------------------</span>
<span class="c"># Get data: this includes outliers</span>
<span class="n">data</span> <span class="o">=</span> <span class="n">fetch_hogg2010test</span><span class="p">()</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">data</span><span class="p">[</span><span class="s">&#39;x&#39;</span><span class="p">]</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">data</span><span class="p">[</span><span class="s">&#39;y&#39;</span><span class="p">]</span>
<span class="n">dy</span> <span class="o">=</span> <span class="n">data</span><span class="p">[</span><span class="s">&#39;sigma_y&#39;</span><span class="p">]</span>


<span class="c"># Define the standard squared-loss function</span>
<span class="k">def</span> <span class="nf">squared_loss</span><span class="p">(</span><span class="n">m</span><span class="p">,</span> <span class="n">b</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">dy</span><span class="p">):</span>
    <span class="n">y_fit</span> <span class="o">=</span> <span class="n">m</span> <span class="o">*</span> <span class="n">x</span> <span class="o">+</span> <span class="n">b</span>
    <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(((</span><span class="n">y</span> <span class="o">-</span> <span class="n">y_fit</span><span class="p">)</span> <span class="o">/</span> <span class="n">dy</span><span class="p">)</span> <span class="o">**</span> <span class="mi">2</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>


<span class="c"># Define the log-likelihood via the Huber loss function</span>
<span class="k">def</span> <span class="nf">huber_loss</span><span class="p">(</span><span class="n">m</span><span class="p">,</span> <span class="n">b</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">dy</span><span class="p">,</span> <span class="n">c</span><span class="o">=</span><span class="mi">2</span><span class="p">):</span>
    <span class="n">y_fit</span> <span class="o">=</span> <span class="n">m</span> <span class="o">*</span> <span class="n">x</span> <span class="o">+</span> <span class="n">b</span>
    <span class="n">t</span> <span class="o">=</span> <span class="nb">abs</span><span class="p">((</span><span class="n">y</span> <span class="o">-</span> <span class="n">y_fit</span><span class="p">)</span> <span class="o">/</span> <span class="n">dy</span><span class="p">)</span>
    <span class="n">flag</span> <span class="o">=</span> <span class="n">t</span> <span class="o">&gt;</span> <span class="n">c</span>
    <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">((</span><span class="o">~</span><span class="n">flag</span><span class="p">)</span> <span class="o">*</span> <span class="p">(</span><span class="mf">0.5</span> <span class="o">*</span> <span class="n">t</span> <span class="o">**</span> <span class="mi">2</span><span class="p">)</span> <span class="o">-</span> <span class="p">(</span><span class="n">flag</span><span class="p">)</span> <span class="o">*</span> <span class="n">c</span> <span class="o">*</span> <span class="p">(</span><span class="mf">0.5</span> <span class="o">*</span> <span class="n">c</span> <span class="o">-</span> <span class="n">t</span><span class="p">),</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>

<span class="n">f_squared</span> <span class="o">=</span> <span class="k">lambda</span> <span class="n">beta</span><span class="p">:</span> <span class="n">squared_loss</span><span class="p">(</span><span class="n">beta</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">beta</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">x</span><span class="o">=</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="n">y</span><span class="p">,</span> <span class="n">dy</span><span class="o">=</span><span class="n">dy</span><span class="p">)</span>
<span class="n">f_huber</span> <span class="o">=</span> <span class="k">lambda</span> <span class="n">beta</span><span class="p">:</span> <span class="n">huber_loss</span><span class="p">(</span><span class="n">beta</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">beta</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">x</span><span class="o">=</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="n">y</span><span class="p">,</span> <span class="n">dy</span><span class="o">=</span><span class="n">dy</span><span class="p">,</span> <span class="n">c</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

<span class="c">#------------------------------------------------------------</span>
<span class="c"># compute the maximum likelihood using the huber loss</span>
<span class="n">beta0</span> <span class="o">=</span> <span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">30</span><span class="p">)</span>
<span class="n">beta_squared</span> <span class="o">=</span> <span class="n">optimize</span><span class="o">.</span><span class="n">fmin</span><span class="p">(</span><span class="n">f_squared</span><span class="p">,</span> <span class="n">beta0</span><span class="p">)</span>
<span class="n">beta_huber</span> <span class="o">=</span> <span class="n">optimize</span><span class="o">.</span><span class="n">fmin</span><span class="p">(</span><span class="n">f_huber</span><span class="p">,</span> <span class="n">beta0</span><span class="p">)</span>

<span class="k">print</span> <span class="n">beta_squared</span>
<span class="k">print</span> <span class="n">beta_huber</span>

<span class="c">#------------------------------------------------------------</span>
<span class="c"># Plot the results</span>
<span class="n">fig</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">6</span><span class="p">,</span> <span class="mi">6</span><span class="p">))</span>
<span class="n">ax</span> <span class="o">=</span> <span class="n">fig</span><span class="o">.</span><span class="n">add_subplot</span><span class="p">(</span><span class="mi">111</span><span class="p">)</span>

<span class="n">x_fit</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">350</span><span class="p">,</span> <span class="mi">10</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x_fit</span><span class="p">,</span> <span class="n">beta_squared</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">*</span> <span class="n">x_fit</span> <span class="o">+</span> <span class="n">beta_squared</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="s">&#39;--k&#39;</span><span class="p">,</span>
        <span class="n">label</span><span class="o">=</span><span class="s">&quot;squared loss:</span><span class="se">\n</span><span class="s"> $y=</span><span class="si">%.2f</span><span class="s">x + </span><span class="si">%.1f</span><span class="s">$&quot;</span> <span class="o">%</span> <span class="nb">tuple</span><span class="p">(</span><span class="n">beta_squared</span><span class="p">))</span>
<span class="n">ax</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x_fit</span><span class="p">,</span> <span class="n">beta_huber</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">*</span> <span class="n">x_fit</span> <span class="o">+</span> <span class="n">beta_huber</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="s">&#39;-k&#39;</span><span class="p">,</span>
        <span class="n">label</span><span class="o">=</span><span class="s">&quot;huber loss:</span><span class="se">\n</span><span class="s"> $y=</span><span class="si">%.2f</span><span class="s">x + </span><span class="si">%.1f</span><span class="s">$&quot;</span> <span class="o">%</span> <span class="nb">tuple</span><span class="p">(</span><span class="n">beta_huber</span><span class="p">))</span>
<span class="n">ax</span><span class="o">.</span><span class="n">legend</span><span class="p">(</span><span class="n">loc</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span> <span class="n">prop</span><span class="o">=</span><span class="nb">dict</span><span class="p">(</span><span class="n">size</span><span class="o">=</span><span class="mi">14</span><span class="p">))</span>

<span class="n">ax</span><span class="o">.</span><span class="n">errorbar</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">dy</span><span class="p">,</span> <span class="n">fmt</span><span class="o">=</span><span class="s">&#39;.k&#39;</span><span class="p">,</span> <span class="n">lw</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">ecolor</span><span class="o">=</span><span class="s">&#39;gray&#39;</span><span class="p">)</span>

<span class="n">ax</span><span class="o">.</span><span class="n">set_xlim</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">350</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_ylim</span><span class="p">(</span><span class="mi">100</span><span class="p">,</span> <span class="mi">700</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s">&#39;$x$&#39;</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s">&#39;$y$&#39;</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div align="right"><p><a class="reference download internal" href="../../_downloads/fig_huber_loss.py"><tt class="xref download docutils literal"><span class="pre">[download</span> <span class="pre">source:</span> <span class="pre">fig_huber_loss.py]</span></tt></a></p>
</div></div>


          </div>
        </div>
      </div>
        <div class="clearer"></div>
      </div>
    </div>

    <div class="footer">
        <p style="text-align: center">This documentation is relative
        to astroML version 0.1<p>
        &copy; 2012, Jake Vanderplas.
      Created using <a href="http://sphinx.pocoo.org/">Sphinx</a> 1.1.3. Design by <a href="http://webylimonada.com">Web y Limonada</a>.
    <span style="padding-left: 5ex;">
    <a href="../../_sources/book_figures/chapter8/fig_huber_loss.txt"
	    rel="nofollow">Show this page source</a>
    </span>
    </div>
  </body>
</html>